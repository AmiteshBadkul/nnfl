{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_DP5-ezv0FP"
      },
      "source": [
        "## Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An8Kyfj9vmHm"
      },
      "source": [
        "# importing libraries required\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxWR6xJxwGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7388866-5835-4c5e-bd48-73dab886a1ea"
      },
      "source": [
        "# connecting gdrive to access the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrYAx-PgwWAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a98f91-8589-4b2c-b3fc-a37a1813b478"
      },
      "source": [
        "# finding out current working directory\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9BM4Uzw43y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef246682-df8e-48cb-b615-e9c0b9718abd"
      },
      "source": [
        "# changing directory to - 'drive/MyDrive/NNFL/Data_A1/'\n",
        "%cd drive/MyDrive/NNFL/Data_A1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwJD97di9hRq"
      },
      "source": [
        "# defining plotting style\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f6IXQ0Fg6X"
      },
      "source": [
        "#Q7\n",
        "Repeat Q7 using a 5-fold CV-based selection of training and test instances for each model. Evaluate the accuracy, sensitivity, and specificity values of multiclass LoR, multiclass LoR+L2-norm regularization, multiclass LoR+L1-norm regularization models using BGD, SGD, and MBGD algorithms. Evaluate the performance of each model using individual accuracy and overall accuracy measures. You must use the dataset data_q6_q7.txt for this question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4G4fm3bCi2U"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkIPlmwKF7nE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472f8a63-47a6-44e8-b6c2-484bb4d1713a"
      },
      "source": [
        "def LogisticRegressionBGDL1(train, theta, alpha, class_label, lambd = 0.0005):\n",
        "    #Preparing the training data ( separating from the class label )\n",
        "    X = np.array(train.iloc[:, :-1])\n",
        "    # Training class data \n",
        "    Y = np.array(train.iloc[:, -1])\n",
        "    #    Making the classes other than wanted to 0 and the wanted to 1\n",
        "    m = Y.shape[0]\n",
        "    for i in range(len(Y)):\n",
        "        if(Y[i] != class_label):\n",
        "            Y[i] = 0\n",
        "        else:\n",
        "            Y[i] = 1\n",
        "    for i in range(1000):\n",
        "        #    Finding the value of z\n",
        "        z = np.dot(X, theta)\n",
        "        #    Putting it in the calculate the value of h(Z)\n",
        "        h = sigmoid(z)\n",
        "        #    Calculating the gradient \n",
        "        gradient = np.dot(X.T, (h-Y)) / m\n",
        "        #    Updating the Theta values\n",
        "        theta -= alpha * gradient - alpha*lambd*np.sign(theta)\n",
        "    return theta\n",
        "\n",
        "\n",
        "print('BGD L1 Regularization: ')\n",
        "print(\"-------------------------------------------------------------------------------------------------\")\n",
        "#reading the file\n",
        "data = pd.read_csv('data_q6_q7.txt', sep=\"\\t\", header = None, engine='python')\n",
        "# making the first as zeroes : \n",
        "data= np.concatenate((np.ones(shape = (data.shape[0],1)),data) ,axis = 1)\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "#normalization of data\n",
        "norma = data.iloc[ :,1:-1]\n",
        "data.iloc[ :,1:-1] = (norma - norma.mean() ) / norma.std()\n",
        "\n",
        "#INtitializing random values to theta vector \n",
        "Theta = np.random.randn(1,8).ravel()\n",
        "\n",
        "#taking the learning rate alpha\n",
        "alpha = 0.01\n",
        "\n",
        "#Randomizing the dataset \n",
        "data = data.sample(frac=1,random_state=random.randint(1,1000))\n",
        "\n",
        "#THe size of each fold \n",
        "sz = int(len(data) * 0.2)\n",
        "\n",
        "start, end, final_accuracy = 0, 0, 0\n",
        "for i in range(5):\n",
        "#    starting index\n",
        "    start = i*sz\n",
        "#    ending index \n",
        "    end = (i+1)*sz\n",
        "    if(i == 4):\n",
        "#        If its the last row do this \n",
        "        end = len(data)\n",
        "#   Separating the train and the test sets \n",
        "    train = data.iloc[start:end, :]\n",
        "    test = data.drop(train.index)\n",
        "#    Making copies of theta ..\n",
        "    T1= Theta.copy()\n",
        "    T2= Theta.copy()\n",
        "    T3= Theta.copy()\n",
        "#    making copies of training sets \n",
        "    Tr1 = train.copy()\n",
        "    Tr2 = train.copy()\n",
        "    Tr3 = train.copy()\n",
        "#    Finding the values thetas ...\n",
        "    theta_1 = LogisticRegressionBGDL1(Tr1, T1,  alpha, 1)\n",
        "    theta_2 = LogisticRegressionBGDL1(Tr2, T2,  alpha, 2)\n",
        "    theta_3 = LogisticRegressionBGDL1(Tr3, T3,  alpha, 3)\n",
        "# taking the values of accuracies into these variables \n",
        "    a1, a2, a3, a = Accuracy(test, theta_1, theta_2, theta_3)\n",
        "    final_accuracy += a\n",
        "# Printing the values of accuracies    \n",
        "    print(\"Individual class accuracies for Fold {}:\\nFor Class 1 : {}\\nFor Class 2 : {}\\nFor Class 3 : {}\".format(i+1, round(a1, 4)*100, round(a2, 5)*100, round(a3, 2)*100))\n",
        "    print(\"One vs All overall accuracy for Fold {}: {}\".format(i+1, round(a, 3)*100))\n",
        "    print(\"-------------------------------------------------------------------------------------------------\")\n",
        "final_accuracy /= 5\n",
        "print(\"Average overall accuracy: {}\".format(round(final_accuracy, 2)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGD L1 Regularization: \n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 1:\n",
            "For Class 1 : 81.82000000000001\n",
            "For Class 2 : 96.226\n",
            "For Class 3 : 88.0\n",
            "One vs All overall accuracy for Fold 1: 88.7\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 2:\n",
            "For Class 1 : 82.46\n",
            "For Class 2 : 96.491\n",
            "For Class 3 : 94.0\n",
            "One vs All overall accuracy for Fold 2: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 3:\n",
            "For Class 1 : 78.57\n",
            "For Class 2 : 98.246\n",
            "For Class 3 : 96.0\n",
            "One vs All overall accuracy for Fold 3: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 4:\n",
            "For Class 1 : 73.68\n",
            "For Class 2 : 98.148\n",
            "For Class 3 : 91.0\n",
            "One vs All overall accuracy for Fold 4: 87.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 5:\n",
            "For Class 1 : 76.36\n",
            "For Class 2 : 96.61\n",
            "For Class 3 : 96.0\n",
            "One vs All overall accuracy for Fold 5: 89.9\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Average overall accuracy: 90.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrEeZlMU646-",
        "outputId": "79146d0b-0d43-4ad2-9718-afd0382fb8c7"
      },
      "source": [
        "def LogisticRegressionBGDL2(train, theta, alpha, class_label, lambd = 0.0001):\n",
        "    #Preparing the training data ( separating from the class label )\n",
        "    X = np.array(train.iloc[:, :-1])\n",
        "    # Training class data \n",
        "    Y = np.array(train.iloc[:, -1])\n",
        "    #    Making the classes other than wanted to 0 and the wanted to 1\n",
        "    m = Y.shape[0]\n",
        "    for i in range(len(Y)):\n",
        "        if(Y[i] != class_label):\n",
        "            Y[i] = 0\n",
        "        else:\n",
        "            Y[i] = 1\n",
        "    for i in range(1000):\n",
        "        #    Finding the value of z\n",
        "        z = np.dot(X, theta)\n",
        "        #    Putting it in the calculate the value of h(Z)\n",
        "        h = sigmoid(z)\n",
        "        #    Calculating the gradient \n",
        "        gradient = np.dot(X.T, (h-Y)) / m\n",
        "        #    Updating the Theta values\n",
        "        theta -= alpha * gradient - alpha*lambd*(theta)\n",
        "    return theta\n",
        "\n",
        "\n",
        "print('BGD L2 Regularization: ')\n",
        "print(\"-------------------------------------------------------------------------------------------------\")\n",
        "#reading the file\n",
        "data = pd.read_csv('data_q6_q7.txt', sep=\"\\t\", header = None, engine='python')\n",
        "# making the first as zeroes : \n",
        "data= np.concatenate((np.ones(shape = (data.shape[0],1)),data) ,axis = 1)\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "#normalization of data\n",
        "norma = data.iloc[ :,1:-1]\n",
        "data.iloc[ :,1:-1] = (norma - norma.mean() ) / norma.std()\n",
        "\n",
        "#INtitializing random values to theta vector \n",
        "Theta = np.random.randn(1,8).ravel()\n",
        "\n",
        "#taking the learning rate alpha\n",
        "alpha = 0.1\n",
        "\n",
        "#Randomizing the dataset \n",
        "data = data.sample(frac=1,random_state=random.randint(1,1000))\n",
        "\n",
        "#THe size of each fold \n",
        "sz = int(len(data) * 0.2)\n",
        "\n",
        "start, end, final_accuracy = 0, 0, 0\n",
        "for i in range(5):\n",
        "#    starting index\n",
        "    start = i*sz\n",
        "#    ending index \n",
        "    end = (i+1)*sz\n",
        "    if(i == 4):\n",
        "#        If its the last row do this \n",
        "        end = len(data)\n",
        "#   Separating the train and the test sets \n",
        "    train = data.iloc[start:end, :]\n",
        "    test = data.drop(train.index)\n",
        "#    Making copies of theta ..\n",
        "    T1= Theta.copy()\n",
        "    T2= Theta.copy()\n",
        "    T3= Theta.copy()\n",
        "#    making copies of training sets \n",
        "    Tr1 = train.copy()\n",
        "    Tr2 = train.copy()\n",
        "    Tr3 = train.copy()\n",
        "#    Finding the values thetas ...\n",
        "    theta_1 = LogisticRegressionBGDL2(Tr1, T1,  alpha, 1)\n",
        "    theta_2 = LogisticRegressionBGDL2(Tr2, T2,  alpha, 2)\n",
        "    theta_3 = LogisticRegressionBGDL2(Tr3, T3,  alpha, 3)\n",
        "# taking the values of accuracies into these variables \n",
        "    a1, a2, a3, a = Accuracy(test, theta_1, theta_2, theta_3)\n",
        "    final_accuracy += a\n",
        "# Printing the values of accuracies    \n",
        "    print(\"Individual class accuracies for Fold {}:\\nFor Class 1 : {}\\nFor Class 2 : {}\\nFor Class 3 : {}\".format(i+1, round(a1, 4)*100, round(a2, 5)*100, round(a3, 2)*100))\n",
        "    print(\"One vs All overall accuracy for Fold {}: {}\".format(i+1, round(a, 3)*100))\n",
        "    print(\"-------------------------------------------------------------------------------------------------\")\n",
        "final_accuracy /= 5\n",
        "print(\"Average overall accuracy: {}\".format(round(final_accuracy, 3)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGD L2 Regularization: \n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 1:\n",
            "For Class 1 : 79.25\n",
            "For Class 2 : 100.0\n",
            "For Class 3 : 93.0\n",
            "One vs All overall accuracy for Fold 1: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 2:\n",
            "For Class 1 : 87.72\n",
            "For Class 2 : 98.182\n",
            "For Class 3 : 98.0\n",
            "One vs All overall accuracy for Fold 2: 94.6\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 3:\n",
            "For Class 1 : 87.92999999999999\n",
            "For Class 2 : 96.364\n",
            "For Class 3 : 89.0\n",
            "One vs All overall accuracy for Fold 3: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 4:\n",
            "For Class 1 : 82.46\n",
            "For Class 2 : 96.154\n",
            "For Class 3 : 95.0\n",
            "One vs All overall accuracy for Fold 4: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 5:\n",
            "For Class 1 : 89.09\n",
            "For Class 2 : 96.552\n",
            "For Class 3 : 95.0\n",
            "One vs All overall accuracy for Fold 5: 93.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Average overall accuracy: 92.30000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaOer3NG9BK1",
        "outputId": "3ab0c5c1-d904-4dca-dbc5-9e29f321e65a"
      },
      "source": [
        "def LogisticRegressionMBGDL2(train, theta, alpha, class_label, lambd = 0.0001):\n",
        "    #Preparing the training data ( separating from the class label )\n",
        "    X = np.array(train.iloc[:, :-1])\n",
        "    # Training class data \n",
        "    Y = np.array(train.iloc[:, -1])\n",
        "    #    Making the classes other than wanted to 0 and the wanted to 1\n",
        "    m = Y.shape[0]\n",
        "    for i in range(len(Y)):\n",
        "        if(Y[i] != class_label):\n",
        "            Y[i] = 0\n",
        "        else:\n",
        "            Y[i] = 1\n",
        "    for i in range(1000):\n",
        "        idx = np.random.randint(len(X), size=8)\n",
        "        #    Finding the value of z\n",
        "        z = np.dot(X[idx], theta)\n",
        "        #    Putting it in the calculate the value of h(Z)\n",
        "        h = sigmoid(z)\n",
        "        #    Calculating the gradient \n",
        "        gradient = np.dot(X[idx].T, (h-Y[idx])) / m\n",
        "        #    Updating the Theta values\n",
        "        theta -= alpha * gradient - alpha*lambd*(theta)\n",
        "    return theta\n",
        "\n",
        "\n",
        "print('MBGD L2 Regularization: ')\n",
        "print(\"-------------------------------------------------------------------------------------------------\")\n",
        "#reading the file\n",
        "data = pd.read_csv('data_q6_q7.txt', sep=\"\\t\", header = None, engine='python')\n",
        "# making the first as zeroes : \n",
        "data= np.concatenate((np.ones(shape = (data.shape[0],1)),data) ,axis = 1)\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "#normalization of data\n",
        "norma = data.iloc[ :,1:-1]\n",
        "data.iloc[ :,1:-1] = (norma - norma.mean() ) / norma.std()\n",
        "\n",
        "#INtitializing random values to theta vector \n",
        "Theta = np.random.randn(1,8).ravel()\n",
        "\n",
        "#taking the learning rate alpha\n",
        "alpha = 0.1\n",
        "\n",
        "#Randomizing the dataset \n",
        "data = data.sample(frac=1,random_state=random.randint(1,1000))\n",
        "\n",
        "#THe size of each fold \n",
        "sz = int(len(data) * 0.2)\n",
        "\n",
        "start, end, final_accuracy = 0, 0, 0\n",
        "for i in range(5):\n",
        "#    starting index\n",
        "    start = i*sz\n",
        "#    ending index \n",
        "    end = (i+1)*sz\n",
        "    if(i == 4):\n",
        "#        If its the last row do this \n",
        "        end = len(data)\n",
        "#   Separating the train and the test sets \n",
        "    train = data.iloc[start:end, :]\n",
        "    test = data.drop(train.index)\n",
        "#    Making copies of theta ..\n",
        "    T1= Theta.copy()\n",
        "    T2= Theta.copy()\n",
        "    T3= Theta.copy()\n",
        "#    making copies of training sets \n",
        "    Tr1 = train.copy()\n",
        "    Tr2 = train.copy()\n",
        "    Tr3 = train.copy()\n",
        "#    Finding the values thetas ...\n",
        "    theta_1 = LogisticRegressionMBGDL2(Tr1, T1,  alpha, 1)\n",
        "    theta_2 = LogisticRegressionMBGDL2(Tr2, T2,  alpha, 2)\n",
        "    theta_3 = LogisticRegressionMBGDL2(Tr3, T3,  alpha, 3)\n",
        "# taking the values of accuracies into these variables \n",
        "    a1, a2, a3, a = Accuracy(test, theta_1, theta_2, theta_3)\n",
        "    final_accuracy += a\n",
        "# Printing the values of accuracies    \n",
        "    print(\"Individual class accuracies for Fold {}:\\nFor Class 1 : {}\\nFor Class 2 : {}\\nFor Class 3 : {}\".format(i+1, round(a1, 4)*100, round(a2, 5)*100, round(a3, 2)*100))\n",
        "    print(\"One vs All overall accuracy for Fold {}: {}\".format(i+1, round(a, 3)*100))\n",
        "    print(\"-------------------------------------------------------------------------------------------------\")\n",
        "final_accuracy /= 5\n",
        "print(\"Average overall accuracy: {}\".format(round(final_accuracy, 3)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MBGD L2 Regularization: \n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 1:\n",
            "For Class 1 : 83.05\n",
            "For Class 2 : 96.552\n",
            "For Class 3 : 92.0\n",
            "One vs All overall accuracy for Fold 1: 90.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 2:\n",
            "For Class 1 : 83.33\n",
            "For Class 2 : 95.082\n",
            "For Class 3 : 94.0\n",
            "One vs All overall accuracy for Fold 2: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 3:\n",
            "For Class 1 : 81.13\n",
            "For Class 2 : 96.552\n",
            "For Class 3 : 93.0\n",
            "One vs All overall accuracy for Fold 3: 90.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 4:\n",
            "For Class 1 : 84.61999999999999\n",
            "For Class 2 : 98.077\n",
            "For Class 3 : 89.0\n",
            "One vs All overall accuracy for Fold 4: 90.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 5:\n",
            "For Class 1 : 70.97\n",
            "For Class 2 : 100.0\n",
            "For Class 3 : 100.0\n",
            "One vs All overall accuracy for Fold 5: 89.3\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Average overall accuracy: 90.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTOT1ksV-zW0",
        "outputId": "08b9d897-8081-4538-d79a-ddf24bdef3e5"
      },
      "source": [
        "def LogisticRegressionMBGDL1(train, theta, alpha, class_label, lambd = 0.0001):\n",
        "    #Preparing the training data ( separating from the class label )\n",
        "    X = np.array(train.iloc[:, :-1])\n",
        "    # Training class data \n",
        "    Y = np.array(train.iloc[:, -1])\n",
        "    #    Making the classes other than wanted to 0 and the wanted to 1\n",
        "    m = Y.shape[0]\n",
        "    for i in range(len(Y)):\n",
        "        if(Y[i] != class_label):\n",
        "            Y[i] = 0\n",
        "        else:\n",
        "            Y[i] = 1\n",
        "    for i in range(1000):\n",
        "        idx = np.random.randint(len(X), size=8)\n",
        "        #    Finding the value of z\n",
        "        z = np.dot(X[idx], theta)\n",
        "        #    Putting it in the calculate the value of h(Z)\n",
        "        h = sigmoid(z)\n",
        "        #    Calculating the gradient \n",
        "        gradient = np.dot(X[idx].T, (h-Y[idx])) / m\n",
        "        #    Updating the Theta values\n",
        "        theta -= alpha * gradient - alpha*lambd*np.sign(theta)\n",
        "    return theta\n",
        "\n",
        "\n",
        "print('MBGD L1 Regularization: ')\n",
        "print(\"-------------------------------------------------------------------------------------------------\")\n",
        "#reading the file\n",
        "data = pd.read_csv('data_q6_q7.txt', sep=\"\\t\", header = None, engine='python')\n",
        "# making the first as zeroes : \n",
        "data= np.concatenate((np.ones(shape = (data.shape[0],1)),data) ,axis = 1)\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "#normalization of data\n",
        "norma = data.iloc[ :,1:-1]\n",
        "data.iloc[ :,1:-1] = (norma - norma.mean() ) / norma.std()\n",
        "\n",
        "#INtitializing random values to theta vector \n",
        "Theta = np.random.randn(1,8).ravel()\n",
        "\n",
        "#taking the learning rate alpha\n",
        "alpha = 0.1\n",
        "\n",
        "#Randomizing the dataset \n",
        "data = data.sample(frac=1,random_state=random.randint(1,1000))\n",
        "\n",
        "#THe size of each fold \n",
        "sz = int(len(data) * 0.2)\n",
        "\n",
        "start, end, final_accuracy = 0, 0, 0\n",
        "for i in range(5):\n",
        "#    starting index\n",
        "    start = i*sz\n",
        "#    ending index \n",
        "    end = (i+1)*sz\n",
        "    if(i == 4):\n",
        "#        If its the last row do this \n",
        "        end = len(data)\n",
        "#   Separating the train and the test sets \n",
        "    train = data.iloc[start:end, :]\n",
        "    test = data.drop(train.index)\n",
        "#    Making copies of theta ..\n",
        "    T1= Theta.copy()\n",
        "    T2= Theta.copy()\n",
        "    T3= Theta.copy()\n",
        "#    making copies of training sets \n",
        "    Tr1 = train.copy()\n",
        "    Tr2 = train.copy()\n",
        "    Tr3 = train.copy()\n",
        "#    Finding the values thetas ...\n",
        "    theta_1 = LogisticRegression(Tr1, T1,  alpha, 1)\n",
        "    theta_2 = LogisticRegression(Tr2, T2,  alpha, 2)\n",
        "    theta_3 = LogisticRegression(Tr3, T3,  alpha, 3)\n",
        "# taking the values of accuracies into these variables \n",
        "    a1, a2, a3, a = Accuracy(test, theta_1, theta_2, theta_3)\n",
        "    final_accuracy += a\n",
        "# Printing the values of accuracies    \n",
        "    print(\"Individual class accuracies for Fold {}:\\nFor Class 1 : {}\\nFor Class 2 : {}\\nFor Class 3 : {}\".format(i+1, round(a1, 4)*100, round(a2, 5)*100, round(a3, 2)*100))\n",
        "    print(\"One vs All overall accuracy for Fold {}: {}\".format(i+1, round(a, 3)*100))\n",
        "    print(\"-------------------------------------------------------------------------------------------------\")\n",
        "final_accuracy /= 5\n",
        "print(\"Average overall accuracy: {}\".format(round(final_accuracy, 3)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MBGD L1 Regularization: \n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 1:\n",
            "For Class 1 : 77.59\n",
            "For Class 2 : 98.214\n",
            "For Class 3 : 94.0\n",
            "One vs All overall accuracy for Fold 1: 89.9\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 2:\n",
            "For Class 1 : 69.49\n",
            "For Class 2 : 98.113\n",
            "For Class 3 : 95.0\n",
            "One vs All overall accuracy for Fold 2: 86.9\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 3:\n",
            "For Class 1 : 77.19\n",
            "For Class 2 : 100.0\n",
            "For Class 3 : 96.0\n",
            "One vs All overall accuracy for Fold 3: 91.10000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 4:\n",
            "For Class 1 : 94.12\n",
            "For Class 2 : 96.491\n",
            "For Class 3 : 87.0\n",
            "One vs All overall accuracy for Fold 4: 92.30000000000001\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 5:\n",
            "For Class 1 : 87.27000000000001\n",
            "For Class 2 : 96.552\n",
            "For Class 3 : 85.0\n",
            "One vs All overall accuracy for Fold 5: 89.9\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Average overall accuracy: 90.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCL5vPJy_6r6",
        "outputId": "67d2dc05-0552-4826-ffb4-01c4ddb26f17"
      },
      "source": [
        "def LogisticRegressionSGDL2(train, theta, alpha, class_label, lambd = 0.0001):\n",
        "    #Preparing the training data ( separating from the class label )\n",
        "    X = np.array(train.iloc[:, :-1])\n",
        "    # Training class data \n",
        "    Y = np.array(train.iloc[:, -1])\n",
        "    #    Making the classes other than wanted to 0 and the wanted to 1\n",
        "    m = Y.shape[0]\n",
        "    for i in range(len(Y)):\n",
        "        if(Y[i] != class_label):\n",
        "            Y[i] = 0\n",
        "        else:\n",
        "            Y[i] = 1\n",
        "    for i in range(1000):\n",
        "        idx = np.random.randint(len(X))\n",
        "        #    Finding the value of z\n",
        "        z = np.dot(X[idx], theta)\n",
        "        #    Putting it in the calculate the value of h(Z)\n",
        "        h = sigmoid(z)\n",
        "        #    Calculating the gradient \n",
        "        gradient = np.dot(X[idx].T, (h-Y[idx])) / m\n",
        "        #    Updating the Theta values\n",
        "        theta -= alpha * gradient - alpha*lambd*(theta)\n",
        "    return theta\n",
        "\n",
        "print('SGD L2 Regularization: ')\n",
        "print(\"-------------------------------------------------------------------------------------------------\")\n",
        "#reading the file\n",
        "data = pd.read_csv('data_q6_q7.txt', sep=\"\\t\", header = None, engine='python')\n",
        "# making the first as zeroes : \n",
        "data= np.concatenate((np.ones(shape = (data.shape[0],1)),data) ,axis = 1)\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "#normalization of data\n",
        "norma = data.iloc[ :,1:-1]\n",
        "data.iloc[ :,1:-1] = (norma - norma.mean() ) / norma.std()\n",
        "\n",
        "#INtitializing random values to theta vector \n",
        "Theta = np.random.randn(1,8).ravel()\n",
        "\n",
        "#taking the learning rate alpha\n",
        "alpha = 0.1\n",
        "\n",
        "#Randomizing the dataset \n",
        "data = data.sample(frac=1,random_state=random.randint(1,1000))\n",
        "\n",
        "#THe size of each fold \n",
        "sz = int(len(data) * 0.2)\n",
        "\n",
        "start, end, final_accuracy = 0, 0, 0\n",
        "for i in range(5):\n",
        "#    starting index\n",
        "    start = i*sz\n",
        "#    ending index \n",
        "    end = (i+1)*sz\n",
        "    if(i == 4):\n",
        "#        If its the last row do this \n",
        "        end = len(data)\n",
        "#   Separating the train and the test sets \n",
        "    train = data.iloc[start:end, :]\n",
        "    test = data.drop(train.index)\n",
        "#    Making copies of theta ..\n",
        "    T1= Theta.copy()\n",
        "    T2= Theta.copy()\n",
        "    T3= Theta.copy()\n",
        "#    making copies of training sets \n",
        "    Tr1 = train.copy()\n",
        "    Tr2 = train.copy()\n",
        "    Tr3 = train.copy()\n",
        "#    Finding the values thetas ...\n",
        "    theta_1 = LogisticRegressionSGDL2(Tr1, T1,  alpha, 1)\n",
        "    theta_2 = LogisticRegressionSGDL2(Tr2, T2,  alpha, 2)\n",
        "    theta_3 = LogisticRegressionSGDL2(Tr3, T3,  alpha, 3)\n",
        "# taking the values of accuracies into these variables \n",
        "    a1, a2, a3, a = Accuracy(test, theta_1, theta_2, theta_3)\n",
        "    final_accuracy += a\n",
        "# Printing the values of accuracies    \n",
        "    print(\"Individual class accuracies for Fold {}:\\nFor Class 1 : {}\\nFor Class 2 : {}\\nFor Class 3 : {}\".format(i+1, round(a1, 4)*100, round(a2, 5)*100, round(a3, 2)*100))\n",
        "    print(\"One vs All overall accuracy for Fold {}: {}\".format(i+1, round(a, 3)*100))\n",
        "    print(\"-------------------------------------------------------------------------------------------------\")\n",
        "final_accuracy /= 5\n",
        "print(\"Average overall accuracy: {}\".format(round(final_accuracy, 3)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD L2 Regularization: \n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 1:\n",
            "For Class 1 : 77.19\n",
            "For Class 2 : 98.0\n",
            "For Class 3 : 87.0\n",
            "One vs All overall accuracy for Fold 1: 86.9\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 2:\n",
            "For Class 1 : 55.169999999999995\n",
            "For Class 2 : 98.214\n",
            "For Class 3 : 98.0\n",
            "One vs All overall accuracy for Fold 2: 83.3\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 3:\n",
            "For Class 1 : 57.379999999999995\n",
            "For Class 2 : 98.113\n",
            "For Class 3 : 98.0\n",
            "One vs All overall accuracy for Fold 3: 83.3\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 4:\n",
            "For Class 1 : 76.47\n",
            "For Class 2 : 98.413\n",
            "For Class 3 : 98.0\n",
            "One vs All overall accuracy for Fold 4: 91.7\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 5:\n",
            "For Class 1 : 77.36\n",
            "For Class 2 : 96.552\n",
            "For Class 3 : 95.0\n",
            "One vs All overall accuracy for Fold 5: 89.9\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Average overall accuracy: 87.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J06pK6J_6r8",
        "outputId": "6ba26074-66f8-470d-df0f-b6058794e000"
      },
      "source": [
        "def LogisticRegressionSGDL1(train, theta, alpha, class_label, lambd = 0.0001):\n",
        "    #Preparing the training data ( separating from the class label )\n",
        "    X = np.array(train.iloc[:, :-1])\n",
        "    # Training class data \n",
        "    Y = np.array(train.iloc[:, -1])\n",
        "    #    Making the classes other than wanted to 0 and the wanted to 1\n",
        "    m = Y.shape[0]\n",
        "    for i in range(len(Y)):\n",
        "        if(Y[i] != class_label):\n",
        "            Y[i] = 0\n",
        "        else:\n",
        "            Y[i] = 1\n",
        "    for i in range(1000):\n",
        "        idx = np.random.randint(len(X))\n",
        "        #    Finding the value of z\n",
        "        z = np.dot(X[idx], theta)\n",
        "        #    Putting it in the calculate the value of h(Z)\n",
        "        h = sigmoid(z)\n",
        "        #    Calculating the gradient \n",
        "        gradient = np.dot(X[idx].T, (h-Y[idx])) / m\n",
        "        #    Updating the Theta values\n",
        "        theta -= alpha * gradient - alpha*lambd*np.sign(theta)\n",
        "    return theta\n",
        "\n",
        "\n",
        "print('SGD L1 Regularization: ')\n",
        "print(\"-------------------------------------------------------------------------------------------------\")\n",
        "#reading the file\n",
        "data = pd.read_csv('data_q6_q7.txt', sep=\"\\t\", header = None, engine='python')\n",
        "# making the first as zeroes : \n",
        "data= np.concatenate((np.ones(shape = (data.shape[0],1)),data) ,axis = 1)\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "#normalization of data\n",
        "norma = data.iloc[ :,1:-1]\n",
        "data.iloc[ :,1:-1] = (norma - norma.mean() ) / norma.std()\n",
        "\n",
        "#INtitializing random values to theta vector \n",
        "Theta = np.random.randn(1,8).ravel()\n",
        "\n",
        "#taking the learning rate alpha\n",
        "alpha = 0.1\n",
        "\n",
        "#Randomizing the dataset \n",
        "data = data.sample(frac=1,random_state=random.randint(1,1000))\n",
        "\n",
        "#THe size of each fold \n",
        "sz = int(len(data) * 0.2)\n",
        "\n",
        "start, end, final_accuracy = 0, 0, 0\n",
        "for i in range(5):\n",
        "#    starting index\n",
        "    start = i*sz\n",
        "#    ending index \n",
        "    end = (i+1)*sz\n",
        "    if(i == 4):\n",
        "#        If its the last row do this \n",
        "        end = len(data)\n",
        "#   Separating the train and the test sets \n",
        "    train = data.iloc[start:end, :]\n",
        "    test = data.drop(train.index)\n",
        "#    Making copies of theta ..\n",
        "    T1= Theta.copy()\n",
        "    T2= Theta.copy()\n",
        "    T3= Theta.copy()\n",
        "#    making copies of training sets \n",
        "    Tr1 = train.copy()\n",
        "    Tr2 = train.copy()\n",
        "    Tr3 = train.copy()\n",
        "#    Finding the values thetas ...\n",
        "    theta_1 = LogisticRegressionSGDL1(Tr1, T1,  alpha, 1)\n",
        "    theta_2 = LogisticRegressionSGDL1(Tr2, T2,  alpha, 2)\n",
        "    theta_3 = LogisticRegressionSGDL1(Tr3, T3,  alpha, 3)\n",
        "# taking the values of accuracies into these variables \n",
        "    a1, a2, a3, a = Accuracy(test, theta_1, theta_2, theta_3)\n",
        "    final_accuracy += a\n",
        "# Printing the values of accuracies    \n",
        "    print(\"Individual class accuracies for Fold {}:\\nFor Class 1 : {}\\nFor Class 2 : {}\\nFor Class 3 : {}\".format(i+1, round(a1, 4)*100, round(a2, 5)*100, round(a3, 2)*100))\n",
        "    print(\"One vs All overall accuracy for Fold {}: {}\".format(i+1, round(a, 3)*100))\n",
        "    print(\"-------------------------------------------------------------------------------------------------\")\n",
        "final_accuracy /= 5\n",
        "print(\"Average overall accuracy: {}\".format(round(final_accuracy, 3)*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD L1 Regularization: \n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 1:\n",
            "For Class 1 : 86.79\n",
            "For Class 2 : 96.429\n",
            "For Class 3 : 88.0\n",
            "One vs All overall accuracy for Fold 1: 90.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 2:\n",
            "For Class 1 : 71.93\n",
            "For Class 2 : 98.246\n",
            "For Class 3 : 94.0\n",
            "One vs All overall accuracy for Fold 2: 88.1\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 3:\n",
            "For Class 1 : 68.42\n",
            "For Class 2 : 100.0\n",
            "For Class 3 : 96.0\n",
            "One vs All overall accuracy for Fold 3: 88.1\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 4:\n",
            "For Class 1 : 59.650000000000006\n",
            "For Class 2 : 96.552\n",
            "For Class 3 : 98.0\n",
            "One vs All overall accuracy for Fold 4: 84.5\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Individual class accuracies for Fold 5:\n",
            "For Class 1 : 71.43\n",
            "For Class 2 : 98.148\n",
            "For Class 3 : 95.0\n",
            "One vs All overall accuracy for Fold 5: 88.1\n",
            "-------------------------------------------------------------------------------------------------\n",
            "Average overall accuracy: 87.9\n"
          ]
        }
      ]
    }
  ]
}