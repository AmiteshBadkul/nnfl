{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q9.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1knRwdnNvqCj",
        "d_DP5-ezv0FP",
        "JU7jcsa-xIRB",
        "fMNYomap2myG",
        "pnJMSX5q-YLD",
        "R19eNOyL4js-",
        "mZ4oDMk24m3_",
        "YeYtNfXc3XEC",
        "_3EuCc5T3ZCQ",
        "Xm40-JlxWyWw",
        "7eitgFeccyGy",
        "6o1wy57UsZeB",
        "lU2ECHP9XF7g",
        "lu52DitxZCxy",
        "mJGLw8OAZCx1",
        "nfJf5A0mexNj",
        "X7uVvLizfVpT",
        "p7a0cqBMq_J3",
        "kgSWwLKVjB_g",
        "k56CwJChquiu",
        "UOKYFcevkN1n",
        "GKoDUet3kYjU",
        "MNgMhw9tywrX",
        "ov0M29UWuHVg",
        "9_X2tKQhusvF",
        "0BRbnnXFogzv",
        "XumIwsW5ogzx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An8Kyfj9vmHm"
      },
      "source": [
        "# importing libraries required\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxWR6xJxwGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f62d28-6108-4f90-f79a-0ac4f94d61e5"
      },
      "source": [
        "# connecting gdrive to access the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrYAx-PgwWAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af0368c-ffcc-4efb-947b-2dd8c62969f6"
      },
      "source": [
        "# finding out current working directory\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9BM4Uzw43y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b8d7f1-d0a1-44ab-f41c-9780b1b54cc1"
      },
      "source": [
        "# changing directory to - 'drive/MyDrive/NNFL/Data_A1/'\n",
        "%cd drive/MyDrive/NNFL/Data_A1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwJD97di9hRq"
      },
      "source": [
        "# defining plotting style\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0nD94QguBE7"
      },
      "source": [
        "def metrics(Y_true, Y_pred):\n",
        "    FP=0 # For counting the False Positives\n",
        "    FN=0 # For counting the False Negatives\n",
        "    TN=0 # For counting the True Negatives\n",
        "    TP=0 # For counting the True Positives\n",
        "\n",
        "    for i in range(len(Y_true)):\n",
        "      if Y_true[i]==1:\n",
        "        if Y_pred[i]==1:\n",
        "          TP+=1\n",
        "        else:\n",
        "          FN+=1\n",
        "      else:\n",
        "        if Y_pred[i]==0:\n",
        "          TN+=1\n",
        "        else:\n",
        "          FP+=1\n",
        "\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "  \n",
        "    print(\"False Positives : \", FP)\n",
        "    print(\"False Negatives : \", FN)\n",
        "    print(\"True Negatives  : \", TN)\n",
        "    print(\"True Positives  : \", TP)\n",
        "\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "\n",
        "    sens= TP/(TP+FN)\n",
        "    spes = TN/(TN+FP)\n",
        "\n",
        "    print(\"Sensitivity : \", sens)\n",
        "    print(\"Specificity : \", spes)\n",
        "    print(\"Accuracy ((TN+TP)/(TN+TP+FN+FP)) : \", ((TP+TN)/(TN+FN+TP+FP)))\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qU_4Bg-yBHd"
      },
      "source": [
        "def normalize(data):\n",
        "  normalized_vec = data\n",
        "\n",
        "  if(len(data.shape) == 1):\n",
        "    mean = np.mean(data[:])\n",
        "    std_dev = np.std(data[:])\n",
        "    normalized_vec[:] = (normalized_vec[:] - mean)/std_dev\n",
        "  else:\n",
        "    for i in range(1,data.shape[1]):\n",
        "      mean = np.mean(data[:, i])\n",
        "      std_dev = np.std(data[:, i])\n",
        "      normalized_vec[:,i] = (normalized_vec[:,i] - mean)/std_dev\n",
        "  \n",
        "  return normalized_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ry6s_8C1Tg5"
      },
      "source": [
        "#Q9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLIuvjTUM3CL"
      },
      "source": [
        "def LH_function_MAP(X, cov, mean):\n",
        "    return ((1 / (np.power((2 * np.pi), X.shape[0] / 2) * np.sqrt(np.linalg.det(cov)))) * np.exp(-0.5 * (((X - mean)).dot((np.linalg.inv(cov)).dot((X - mean).T)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKBhWA7SM9G3"
      },
      "source": [
        "def mean(data): \n",
        "    mean_val = []\n",
        "    data = np.array(data)\n",
        "    for i in range(data.shape[1]):\n",
        "        mean_val.append(np.sum(data[:,i])/len(data))\n",
        "    return mean_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuVaJYhzOK8z"
      },
      "source": [
        "def MAP(XVec_test,Y_Prob,mean_val,cov):\n",
        "  res = []\n",
        "  for i in range(len(mean_val)):\n",
        "    res.append(LH_function_MAP(XVec_test,cov[i],mean_val[i])*Y_Prob[i])\n",
        "  return (np.argmax(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBzaKQ68LId9"
      },
      "source": [
        "def fiveCVMAP(filename):\n",
        "  # obtaining the data from the file\n",
        "  df = pd.read_csv(filename, sep=\"\\t\", header = None, engine='python')\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "  # df.insert(0, 'ones', 1)\n",
        "\n",
        "\n",
        "  fold_length = int((df.shape[0])/5)\n",
        "\n",
        "  # preparing the data for 5 fold CV\n",
        "  cv_val = 5\n",
        "\n",
        "  cv_lists = [[] for i in range(0, cv_val)]\n",
        "  fold_np = [[] for i in range(0, cv_val)]\n",
        "  \n",
        "  for i in range(cv_val):\n",
        "    cv_lists[i] = df[i*fold_length:(i+1)*fold_length]\n",
        "    fold_np[i] = cv_lists[i].to_numpy()\n",
        "\n",
        "  for iteration in range(cv_val):\n",
        "    test_data = None\n",
        "    train_data = None\n",
        "    train_list  = []\n",
        "    for j in range(cv_val):\n",
        "      if(i==j):\n",
        "        test_data = fold_np[iteration]\n",
        "      else:\n",
        "        train_list.append(cv_lists[iteration])\n",
        "\n",
        "    train_data = np.vstack(train_list)\n",
        "\n",
        "    print('Fold: ', iteration+1)\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "    # normalizing data\n",
        "    XVec_train = normalize(train_data[:, :(train_data.shape[1]-1)])\n",
        "    YVec_train = train_data[:,train_data.shape[1]-1]\n",
        "\n",
        "    XVec_test = normalize(test_data[:, :(test_data.shape[1]-1)])\n",
        "    YVec_test = test_data[:,test_data.shape[1]-1]\n",
        "    MAP_CV(XVec_train, YVec_train, XVec_test, YVec_test)\n",
        "    print('--------------------------------------------------------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiDybk2JUq7S"
      },
      "source": [
        "def MAP_CV(XVec_train, YVec_train, XVec_test, YVec_test):\n",
        "  Y_Prob = []\n",
        "  mean_val = []\n",
        "  cov = []\n",
        "  for j in np.unique(YVec_train):\n",
        "    Y_Prob.append(len([i for (i, val) in enumerate(YVec_train) if val == j])/len(YVec_train))\n",
        "    x = np.array([XVec_train[i] for (i, val) in enumerate(YVec_train) if val == j])\n",
        "    mean_val.append(mean(x));\n",
        "    cov.append(np.cov(x.T))\n",
        "  mean_val = np.array(mean_val)\n",
        "  cov = np.array(cov)\n",
        "\n",
        "  Y_Pred=[]\n",
        "  for i in range(len(XVec_test)):\n",
        "    Y_Pred.append(MAP(XVec_test[i],Y_Prob,mean_val,cov)+1)\n",
        "\n",
        "  Y_Pred=np.array(Y_Pred)\n",
        "  df_confusion = pd.crosstab(YVec_test, Y_Pred)\n",
        "\n",
        "  df_confusion=np.array(df_confusion)\n",
        "  row_sum=0.0;\n",
        "  overall_sum=0.0;\n",
        "  dia_el=0.0\n",
        "\n",
        "  print(\"\\n Confusion Matrix\\n\", df_confusion)\n",
        "\n",
        "  for i in range(df_confusion.shape[0]):\n",
        "    row_sum=np.sum(df_confusion[i,:])\n",
        "    overall_sum +=row_sum\n",
        "    acc=(df_confusion[i,i]/row_sum)\n",
        "    dia_el+=df_confusion[i,i]\n",
        "    print(\"Accuracy for class \"+str(i+1)+\" is {}\".format(acc))\n",
        "  \n",
        "\n",
        "  ov_acc=((dia_el/overall_sum))\n",
        "  print(\"Overall Accuracy for the model is {}\".format(ov_acc))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O86aTdGZpma8",
        "outputId": "0fd04ee1-3699-422d-de93-215b9f60ba2f"
      },
      "source": [
        "fiveCVMAP('data_q6_q7.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold:  1\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " Confusion Matrix\n",
            " [[14  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 18]]\n",
            "Accuracy for class 1 is 1.0\n",
            "Accuracy for class 2 is 1.0\n",
            "Accuracy for class 3 is 1.0\n",
            "Overall Accuracy for the model is 1.0\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  2\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " Confusion Matrix\n",
            " [[16  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n",
            "Accuracy for class 1 is 1.0\n",
            "Accuracy for class 2 is 1.0\n",
            "Accuracy for class 3 is 1.0\n",
            "Overall Accuracy for the model is 1.0\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  3\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " Confusion Matrix\n",
            " [[14  0  0]\n",
            " [ 0 19  0]\n",
            " [ 0  0  9]]\n",
            "Accuracy for class 1 is 1.0\n",
            "Accuracy for class 2 is 1.0\n",
            "Accuracy for class 3 is 1.0\n",
            "Overall Accuracy for the model is 1.0\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  4\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " Confusion Matrix\n",
            " [[13  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0 15]]\n",
            "Accuracy for class 1 is 1.0\n",
            "Accuracy for class 2 is 1.0\n",
            "Accuracy for class 3 is 1.0\n",
            "Overall Accuracy for the model is 1.0\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  5\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " Confusion Matrix\n",
            " [[13  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0 15]]\n",
            "Accuracy for class 1 is 1.0\n",
            "Accuracy for class 2 is 1.0\n",
            "Accuracy for class 3 is 1.0\n",
            "Overall Accuracy for the model is 1.0\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}