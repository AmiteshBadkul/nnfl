{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kL1ugGKAEgK"
      },
      "source": [
        "# NNFL Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omj7b7rT_iRC",
        "outputId": "84d8f314-031a-4abc-afc0-6bdc11708e8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmgBJdcAAz5",
        "outputId": "ea25fe4a-d619-4780-e459-246ffa54923a"
      },
      "source": [
        "# Changing directory to the directory containing dataset\n",
        "%cd drive/MyDrive/NNFL/Data_A2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meFTsfIpAeGP",
        "outputId": "1fb8a342-2162-4262-f703-1f2d6d6a2c49"
      },
      "source": [
        "# listing datasets\n",
        "%ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1234719\n",
            "-rw------- 1 root root     637638 Oct 31 04:55 Assignment2.pdf\n",
            "-rw------- 1 root root        259 Oct 31 04:57 class_label.mat\n",
            "-rw------- 1 root root      40295 Oct 31 04:57 data55.xlsx\n",
            "-rw------- 1 root root      21269 Oct 31 04:55 data5.xlsx\n",
            "-rw------- 1 root root 1263647365 Oct 31 04:58 input.mat\n",
            "drwx------ 2 root root       4096 Nov 18 05:58 \u001b[0m\u001b[01;34mlogs\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "monX5050Awmc"
      },
      "source": [
        "# libraries required\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wDLjGQSaEU"
      },
      "source": [
        "# supressing warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLoM8rZLV7hL"
      },
      "source": [
        "# Q4\n",
        "Implement the radial basis function neural network (RBFNN) for the classification problem. You can use\n",
        "Gaussian, multiquadric and linear kernel functions for the implementation. You can use both holdout (70,\n",
        "10, and 20%) and 5-fold cross-validation approaches for evaluating the performance of the classifier. The\n",
        "classification performance must be evaluated using individual accuracy and overall accuracy measures.\n",
        "The dataset (data5.xlsx) contains 7 features and the last column is the output (class labels). (Packages\n",
        "such as Scikitlearn, keras, tensorflow, pytorch etc. are not allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v19SDl_JvmdZ"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def kmeansClustering(k):\n",
        "    kmeans = KMeans(n_clusters = k).fit(train_x)\n",
        "    return kmeans\n",
        "\n",
        "def kernel_func(x, std, sigma, kernalFunction):\n",
        "    beta = 1/(2*sigma*sigma)\n",
        "    if kernalFunction == \"Gaussian\":\n",
        "        return np.exp(-beta*(np.linalg.norm(x-std))**2)\n",
        "    elif kernalFunction == \"MultiQuadratic\":\n",
        "        return ((np.linalg.norm(x-std))**2+sigma**2)**0.5\n",
        "    elif kernalFunction == \"Linear\":\n",
        "        return np.linalg.norm(x-std)\n",
        "\n",
        "def sigmaComputation(x, labels, std):\n",
        "    c = std.shape[0]\n",
        "    sigma = np.zeros(c)\n",
        "    for i in range(c):\n",
        "        x_temp = x[labels==i]\n",
        "        k = 0\n",
        "        for j in range(x_temp.shape[0]):\n",
        "            k+=np.linalg.norm(x_temp[j]-std[i])\n",
        "        sigma[i] = k/x_temp.shape[0]\n",
        "    return sigma\n",
        "\n",
        "def hypothesisCalc(X, std, sigma, kernalFunction):\n",
        "    c = std.shape[0]\n",
        "    H = np.zeros((X.shape[0],c))\n",
        "    for i in range(H.shape[0]):\n",
        "        for j in range(H.shape[1]):\n",
        "            H[i][j]=kernel_func(X[i],std[j],sigma[j],kernalFunction)\n",
        "    return H\n",
        "\n",
        "def compute(train_x, train_y, test_x, test_y, kernalFunction):\n",
        "    kmeans = kmeansClustering(20)\n",
        "    std = kmeans.cluster_centers_\n",
        "    sigma = sigmaComputation(train_x,kmeans.labels_,std)\n",
        "    H = hypothesisCalc(train_x,std,sigma,kernalFunction)\n",
        "    W = np.dot(np.linalg.pinv(H),train_y)\n",
        "    H = hypothesisCalc(test_x,std,sigma,kernalFunction)\n",
        "    pred = np.dot(H,W)\n",
        "    p = (pred>0.5).astype(int)\n",
        "    a = (p!=test_y).astype(int)\n",
        "    metrics(test_y, pred_y) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv7EI9DGvosZ"
      },
      "source": [
        "def resultQ4(filename = 'data5.xlsx'):\n",
        "  dataset = pd.read_excel(filename, header = None)\n",
        "\n",
        "  row, col = dataset.shape\n",
        "  feats = col - 1 \n",
        "\n",
        "  # normalization\n",
        "  dataset.loc[:, dataset.columns != feats] = (dataset.loc[:, dataset.columns != feats]-dataset.loc[:, dataset.columns != feats].mean(axis=0))/dataset.loc[:, dataset.columns != feats].std(axis=0)\n",
        "  \n",
        "  # spliting dataset into train test and val\n",
        "  training_data, validation_data, testing_data = np.split(dataset.sample(frac=1),[int(0.7*len(dataset)), int(0.8*len(dataset))])\n",
        "\n",
        "  training_data = np.array(training_data)\n",
        "  validation_data = np.array(validation_data)\n",
        "  testing_data = np.array(testing_data)\n",
        "  training_data_X = training_data[:, :feats]\n",
        "  training_data_y = training_data[:, feats]\n",
        "  validation_data_X = validation_data[:, :feats]\n",
        "  validation_data_y = validation_data[:, feats]\n",
        "  testing_data_X = testing_data[:, :feats]\n",
        "  testing_data_y = testing_data[:, feats]\n",
        "\n",
        "  train_row, train_col = training_data_X.shape\n",
        "\n",
        "  print('Linear Kernel')\n",
        "  compute(training_data_X, training_data_y, testing_data_X, testing_data_y, \"Linear\")\n",
        "  compute(training_data_X, training_data_y, validation_data_X, validation_data_y, \"Linear\")\n",
        "\n",
        "  print('Multi Quadratic Kernel')\n",
        "  compute(training_data_X, training_data_y, testing_data_X, testing_data_y, \"MultiQuadratic\")\n",
        "  compute(training_data_X, training_data_y, validation_data_X, validation_data_y, \"MultiQuadratic\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msDhstLMZCpL",
        "outputId": "99906ff4-f4e5-4701-b21f-3fb137e48d9d"
      },
      "source": [
        "resultQ4()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Kernel\n",
            "Testing Accuracy: \n",
            "\n",
            "Sensitivity :  0.8461538461538461\n",
            "Specificity :  0.7209302325581395\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7804878048780488\n",
            "---------------------------------------------------------------------------\n",
            "Validation Accuracy: \n",
            "\n",
            "Sensitivity :  0.8620689655172413\n",
            "Specificity :  0.9183673469387755\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8878504672897196\n",
            "---------------------------------------------------------------------------\n",
            "Multi Quadratic Kernel\n",
            "Testing Accuracy: \n",
            "\n",
            "Sensitivity :  0.7868852459016393\n",
            "Specificity :  0.8636363636363636\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8267716535433071\n",
            "---------------------------------------------------------------------------\n",
            "Validation Accuracy: \n",
            "\n",
            "Sensitivity :  0.8837209302325582\n",
            "Specificity :  0.803921568627451\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8404255319148937\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}