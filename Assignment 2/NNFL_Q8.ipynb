{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kL1ugGKAEgK"
      },
      "source": [
        "# NNFL Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omj7b7rT_iRC",
        "outputId": "84d8f314-031a-4abc-afc0-6bdc11708e8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmgBJdcAAz5",
        "outputId": "ea25fe4a-d619-4780-e459-246ffa54923a"
      },
      "source": [
        "# Changing directory to the directory containing dataset\n",
        "%cd drive/MyDrive/NNFL/Data_A2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meFTsfIpAeGP",
        "outputId": "1fb8a342-2162-4262-f703-1f2d6d6a2c49"
      },
      "source": [
        "# listing datasets\n",
        "%ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1234719\n",
            "-rw------- 1 root root     637638 Oct 31 04:55 Assignment2.pdf\n",
            "-rw------- 1 root root        259 Oct 31 04:57 class_label.mat\n",
            "-rw------- 1 root root      40295 Oct 31 04:57 data55.xlsx\n",
            "-rw------- 1 root root      21269 Oct 31 04:55 data5.xlsx\n",
            "-rw------- 1 root root 1263647365 Oct 31 04:58 input.mat\n",
            "drwx------ 2 root root       4096 Nov 18 05:58 \u001b[0m\u001b[01;34mlogs\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "monX5050Awmc"
      },
      "source": [
        "# libraries required\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wDLjGQSaEU"
      },
      "source": [
        "# supressing warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdAnBAJhdIoV"
      },
      "source": [
        "#Q8\n",
        "Implement support vector machine (SVM) classifier for the multi-class classification task. You can use one\n",
        "vs one and one vs all multiclass coding methods to create binary SVM models. Implement the SMO\n",
        "algorithm for the evaluation of the training parameters of SVM such as Lagrange multipliers. You can use\n",
        "holdout approach (70%, 10%, 20%) for evaluating the performance of the classifier. The dataset\n",
        "(data5.xlsx) contains 7 features and the last column is the output (class labels). Evaluate individual\n",
        "accuracy and overall accuracy. You can use RBF and polynomial kernels. Evaluate the classification\n",
        "performance of multiclass SVM for each kernel function. (Packages such as Scikitlearn, keras, tensorflow,\n",
        "pytorch etc. are not allowed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tcv022cdKtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ff95e9-c8dc-40ae-fd9a-b105e6f707f3"
      },
      "source": [
        "\n",
        "dataset = pd.read_excel('data5.xslx', header = None)\n",
        "\n",
        "row, col = dataset.shape\n",
        "feats = col - 1 \n",
        "\n",
        "# normalization\n",
        "dataset.loc[:, dataset.columns != feats] = (dataset.loc[:, dataset.columns != feats]-dataset.loc[:, dataset.columns != feats].mean(axis=0))/dataset.loc[:, dataset.columns != feats].std(axis=0)\n",
        "\n",
        "# spliting dataset into train test and val\n",
        "training_data, validation_data, testing_data = np.split(dataset.sample(frac=1),[int(0.7*len(dataset)), int(0.8*len(dataset))])\n",
        "\n",
        "training_data = np.array(training_data)\n",
        "validation_data = np.array(validation_data)\n",
        "testing_data = np.array(testing_data)\n",
        "training_data_X = training_data[:, :feats]\n",
        "training_data_y = training_data[:, feats]\n",
        "validation_data_X = validation_data[:, :feats]\n",
        "validation_data_y = validation_data[:, feats]\n",
        "testing_data_X = testing_data[:, :feats]\n",
        "testing_data_y = testing_data[:, feats]\n",
        "\n",
        "train_row, train_col = training_data_X.shape\n",
        "\n",
        "\n",
        "class SupportVec():\n",
        "    def __init__(self, max_iter=10000, kernel_type='linear', C=1.0, epsilon=0.001):\n",
        "        self.kernels = {\n",
        "            'linear' : self.linearKernel\n",
        "        }\n",
        "        self.max_iter = max_iter\n",
        "        self.kernel_type = kernel_type\n",
        "        self.C = C\n",
        "        self.epsilon = epsilon\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        n, d = X.shape[0], X.shape[1]\n",
        "        alpha = np.zeros((n))\n",
        "        kernel = self.kernels[self.kernel_type]\n",
        "        count = 0\n",
        "        while(True):\n",
        "            count += 1\n",
        "            alpha_prev = np.copy(alpha)\n",
        "\n",
        "            for j in range(0, n):\n",
        "                i = self.initRandomize(0, n-1, j) # Get random int i~=j\n",
        "                x_i, x_j, Yi, Yj = X[i,:], X[j,:], y[i], y[j]\n",
        "                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
        "                if k_ij == 0:\n",
        "                    continue\n",
        "                jPrimeAlpha, iPrimeAlpha = alpha[j], alpha[i]\n",
        "                (L, H) = self.computerLH(self.C, jPrimeAlpha, iPrimeAlpha, Yj, Yi)\n",
        "                self.w = self.computeWeights(alpha, y, X)\n",
        "                self.b = self.computeBias(X, y, self.w)   \n",
        "                E_i = self.E(x_i, Yi, self.w, self.b)\n",
        "                E_j = self.E(x_j, Yj, self.w, self.b)\n",
        "\n",
        "                alpha[j] = jPrimeAlpha + float(Yj * (E_i - E_j))/k_ij\n",
        "                alpha[j] = max(alpha[j], L)\n",
        "                alpha[j] = min(alpha[j], H)\n",
        "\n",
        "                alpha[i] = alpha_prime_i + y_i*Yj * (alpha_prime_j - alpha[j])\n",
        "\n",
        "            diff = np.linalg.norm(alpha - alpha_prev)\n",
        "            if diff < self.epsilon:\n",
        "                break\n",
        "            if(count >= self.max_iter):\n",
        "                print(\"Iteration number exceeded the max of %d iterations\" % (self.max_iter))\n",
        "                return\n",
        "\n",
        "        self.b = self.computeBias(X, y, self.w)\n",
        "        if self.kernel_type == 'linear':\n",
        "            self.w = self.computeWeights(alpha, y, X)\n",
        "\n",
        "        alpha_idx = np.where(alpha > 0)[0]\n",
        "        support_vectors = X[alpha_idx, :]\n",
        "        return support_vectors, count\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.h(X, self.w, self.b)\n",
        "\n",
        "    def computeBias(self, X, y, w):\n",
        "        biasVar = y - np.dot(w.T, X.T)\n",
        "        return np.mean(biasVar)\n",
        "\n",
        "    def computeWeights(self, alpha, Y, X):\n",
        "        return np.dot(X.T, np.multiplY(alpha,y))\n",
        "\n",
        "    def h(self, X, weight, bias):\n",
        "        return np.sign(np.dot(weight.T, X.T) + bias).astype(int)\n",
        "\n",
        "    def E(self, Xk, Yk, weight, bias):\n",
        "        return self.h(Xk, weight, bias) - Yk\n",
        "\n",
        "    def computerLH(self, C, jPrimeAlpha, iPrimeAlpha, Yj, Yi):\n",
        "        if(Yi != Yj):\n",
        "            return (max (0, jPrimeAlpha - iPrimeAlpha), min(C, C - iPrimeAlpha + jPrimeAlpha))\n",
        "        else:\n",
        "            return (max (0, iPrimeAlpha + jPrimeAlpha - C), min(C, iPrimeAlpha + jPrimeAlpha))\n",
        "\n",
        "    def initRandomize(self, a, b, count):\n",
        "\n",
        "        iterations =  count\n",
        "\n",
        "        counter  = 0\n",
        "\n",
        "        while(iterations ==  count and counter<1000):\n",
        "            iterations = random.randint(a,b)\n",
        "            counter += 1\n",
        "        return iterations\n",
        "   \n",
        "    def linearKernel(self, x1, x2):\n",
        "        return np.dot(x1, x2.T)\n",
        "\n",
        "model = SupportVec(max_iter=1000, epsilon=0.01)\n",
        "model.fit(training_data_X, training_data_y)\n",
        "test_pred = model.predict(test_x)\n",
        "print('Testing data')\n",
        "metrics(testing_data_y, test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing data\n",
            "---------------------------------------------------------------------------\n",
            "Sensitivity :  0.8653846153846154\n",
            "Specificity :  0.8043478260869565\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8367346938775511\n"
          ]
        }
      ]
    }
  ]
}