{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_DP5-ezv0FP"
      },
      "source": [
        "## Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An8Kyfj9vmHm"
      },
      "source": [
        "# importing libraries required\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxWR6xJxwGLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7388866-5835-4c5e-bd48-73dab886a1ea"
      },
      "source": [
        "# connecting gdrive to access the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrYAx-PgwWAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a98f91-8589-4b2c-b3fc-a37a1813b478"
      },
      "source": [
        "# finding out current working directory\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE9BM4Uzw43y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef246682-df8e-48cb-b615-e9c0b9718abd"
      },
      "source": [
        "# changing directory to - 'drive/MyDrive/NNFL/Data_A1/'\n",
        "%cd drive/MyDrive/NNFL/Data_A1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwJD97di9hRq"
      },
      "source": [
        "# defining plotting style\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xT_8SUcu8i5"
      },
      "source": [
        "# Q5\n",
        "Repeat the Q4 using a 5-fold CV-based selection of training and test instances for each model. Evaluate the accuracy, sensitivity, and specificity values of LoR, LoR+L2-norm regularization, LoR+L1-norm regularization models using BGD, SGD, and MBGD algorithms. You must use the dataset data_q4_q5.xlsx for this question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G6LgaKIvxDN"
      },
      "source": [
        "def fiveFoldCV(filename):\n",
        "  # obtaining the data from the file\n",
        "  df = pd.read_excel(filename)\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "  df.insert(0, 'ones', 1)\n",
        "\n",
        "  # encoding the data\n",
        "  for i in range(len(df)):\n",
        "    if(df['diagnosis'][i] == 'B'):\n",
        "      df['diagnosis'][i] = 0\n",
        "    elif(df['diagnosis'][i] == 'M'):\n",
        "      df['diagnosis'][i] = 1\n",
        "\n",
        "\n",
        "  fold_length = int((df.shape[0])/5)\n",
        "\n",
        "  # preparing the data for 5 fold CV\n",
        "  cv_val = 5\n",
        "\n",
        "  cv_lists = [[] for i in range(0, cv_val)]\n",
        "  fold_np = [[] for i in range(0, cv_val)]\n",
        "  \n",
        "  for i in range(cv_val):\n",
        "    cv_lists[i] = df[i*fold_length:(i+1)*fold_length]\n",
        "    fold_np[i] = cv_lists[i].to_numpy()\n",
        "  \n",
        "  print('--------------------------------------------------------------------------------')  \n",
        "  print('Logistic Regression using L1-norm regularization approach & BGD')\n",
        "  print('--------------------------------------------------------------------------------')  \n",
        "  for iteration in range(cv_val):\n",
        "    test_data = None\n",
        "    train_data = None\n",
        "    train_list  = []\n",
        "    for j in range(cv_val):\n",
        "      if(i==j):\n",
        "        test_data = fold_np[iteration]\n",
        "      else:\n",
        "        train_list.append(cv_lists[iteration])\n",
        "\n",
        "    train_data = np.vstack(train_list)\n",
        "\n",
        "    print('Fold: ', iteration)\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "    # normalizing data\n",
        "    XVec_train = normalize(train_data[:, :(train_data.shape[1]-1)])\n",
        "    YVec_train = train_data[:,train_data.shape[1]-1]\n",
        "\n",
        "    XVec_test = normalize(test_data[:, :(test_data.shape[1]-1)])\n",
        "    YVec_test = test_data[:,test_data.shape[1]-1]\n",
        "\n",
        "    fiveFoldBGD(XVec_train, YVec_train, XVec_test, YVec_test)    \n",
        "\n",
        "  print('--------------------------------------------------------------------------------')  \n",
        "  print('Logistic Regression using L1-norm regularization approach & MBGD')\n",
        "  print('--------------------------------------------------------------------------------')  \n",
        "  for iter in range(cv_val):\n",
        "    test_data = None\n",
        "    train_data = None\n",
        "    train_list  = []\n",
        "    for j in range(cv_val):\n",
        "      if(i==j):\n",
        "        test_data = fold_np[iter]\n",
        "      else:\n",
        "        train_list.append(cv_lists[iter])\n",
        "\n",
        "    train_data = np.vstack(train_list)\n",
        "\n",
        "    print('Fold: ', iter)\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "    # normalizing data\n",
        "    XVec_train = normalize(train_data[:, :(train_data.shape[1]-1)])\n",
        "    YVec_train = train_data[:,train_data.shape[1]-1]\n",
        "\n",
        "    XVec_test = normalize(test_data[:, :(test_data.shape[1]-1)])\n",
        "    YVec_test = test_data[:,test_data.shape[1]-1]\n",
        "\n",
        "    fiveFoldMBGD(XVec_train, YVec_train, XVec_test, YVec_test)    \n",
        "\n",
        "  print('--------------------------------------------------------------------------------')  \n",
        "  print('Logistic Regression using L1-norm regularization approach & SGD')\n",
        "  print('--------------------------------------------------------------------------------')  \n",
        "  for iter in range(cv_val):\n",
        "    test_data = None\n",
        "    train_data = None\n",
        "    train_list  = []\n",
        "    for j in range(cv_val):\n",
        "      if(i==j):\n",
        "        test_data = fold_np[iter]\n",
        "      else:\n",
        "        train_list.append(cv_lists[iter])\n",
        "\n",
        "    train_data = np.vstack(train_list)\n",
        "\n",
        "    print('Fold: ', iter)\n",
        "    print('--------------------------------------------------------------------------------')\n",
        "    # normalizing data\n",
        "    XVec_train = normalize(train_data[:, :(train_data.shape[1]-1)])\n",
        "    YVec_train = train_data[:,train_data.shape[1]-1]\n",
        "\n",
        "    XVec_test = normalize(test_data[:, :(test_data.shape[1]-1)])\n",
        "    YVec_test = test_data[:,test_data.shape[1]-1]\n",
        "\n",
        "    fiveFoldSGD(XVec_train, YVec_train, XVec_test, YVec_test)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJx_VipULSjq"
      },
      "source": [
        "def fiveFoldBGD(XVec_train, YVec_train, XVec_test, YVec_test, epoch = 200, alpha = 0.1, lambd = 0.0005):\n",
        "  W = (np.random.randn((XVec_train.shape)[1])).T\n",
        "  costs = [] # for recording the cost function\n",
        "\n",
        "  for i in range(epoch):\n",
        "    Z = XVec_train.dot(W)\n",
        "    Y_prob = sigmoid(Z)\n",
        "\n",
        "    cost = costFunctionLORL1(YVec_train, Y_prob, W, lambd)\n",
        "    loss = np.mean(cost)\n",
        "    costs.append(loss)\n",
        "\n",
        "    W = W - alpha*np.mean(((Y_prob - YVec_train).reshape(YVec_train.shape[0],1))*XVec_train, axis=0) - alpha*lambd*np.sign(W) # using L1 norm\n",
        "\n",
        "    #print('EPOCH : {}  &  LOSS : {}'.format(i, loss))\n",
        "  \n",
        "  Y_pred_train = predictLORL1(XVec_train, W)\n",
        "  Y_pred_test = predictLORL1(normalize(XVec_test), W)\n",
        "\n",
        "  print(\"Metrics measured for training data\")\n",
        "  metrics(YVec_train, Y_pred_train)\n",
        "  print(\"Metrics measured for testing data\")\n",
        "  metrics(YVec_test, Y_pred_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-deuYjUwawA"
      },
      "source": [
        "def fiveFoldMBGD(XVec_train, YVec_train, XVec_test, YVec_test, epoch = 300, alpha = 0.075, lambd = 0.0005, batch_size = 50):\n",
        "  W = (np.random.randn((XVec_train.shape)[1])).T\n",
        "  costs = [] # for recording the cost function\n",
        "\n",
        "  for i in range(epoch):\n",
        "    Z = XVec_train.dot(W)\n",
        "    Y_prob = sigmoid(Z)\n",
        "\n",
        "    cost = costFunctionLORL1(YVec_train, Y_prob, W, lambd)\n",
        "    loss = np.mean(cost)\n",
        "    costs.append(loss)\n",
        "\n",
        "    idx = np.random.randint(0,XVec_train.shape[0], size=batch_size)\n",
        "    W = W - alpha*np.mean(((Y_prob[idx] - YVec_train[idx])).dot(XVec_train[idx]), axis=0) - alpha*lambd*np.sign(W)\n",
        "\n",
        "    #print('EPOCH : {}  &  LOSS : {}'.format(i, loss))\n",
        "  \n",
        "  Y_pred_train = predictLORL1(XVec_train, W)\n",
        "  Y_pred_test = predictLORL1(normalize(XVec_test), W)\n",
        "\n",
        "  print(\"Metrics measured for training data\")\n",
        "  metrics(YVec_train, Y_pred_train)\n",
        "  print(\"Metrics measured for testing data\")\n",
        "  metrics(YVec_test, Y_pred_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxbSnDG30D-S"
      },
      "source": [
        "def fiveFoldSGD(XVec_train, YVec_train, XVec_test, YVec_test, epoch = 300, alpha = 0.075, lambd = 0.0005):\n",
        "  W = (np.random.randn((XVec_train.shape)[1])).T\n",
        "  costs = [] # for recording the cost function\n",
        "\n",
        "  for i in range(epoch):\n",
        "    Z = XVec_train.dot(W)\n",
        "    Y_prob = sigmoid(Z)\n",
        "\n",
        "    cost = costFunctionLORL1(YVec_train, Y_prob, W, lambd)\n",
        "    loss = np.mean(cost)\n",
        "    costs.append(loss)\n",
        "\n",
        "    idx = np.random.randint(0,XVec_train.shape[0])\n",
        "    W = W - alpha*np.mean(((Y_prob[idx] - YVec_train[idx]))*(XVec_train[idx]), axis=0) - alpha*lambd*np.sign(W)\n",
        "\n",
        "    #print('EPOCH : {}  &  LOSS : {}'.format(i, loss))\n",
        "  \n",
        "  Y_pred_train = predictLORL1(XVec_train, W)\n",
        "  Y_pred_test = predictLORL1(normalize(XVec_test), W)\n",
        "\n",
        "  print(\"Metrics measured for training data\")\n",
        "  metrics(YVec_train, Y_pred_train)\n",
        "  print(\"Metrics measured for testing data\")\n",
        "  metrics(YVec_test, Y_pred_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAnmlgh5v8v6",
        "outputId": "14c363f4-51e1-45f3-9c19-bfa32df2104b"
      },
      "source": [
        "fiveFoldCV('data_q4_q5.xlsx')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Logistic Regression using L1-norm regularization approach & BGD\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  0\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  12\n",
            "False Negatives :  8\n",
            "True Negatives  :  312\n",
            "True Positives  :  120\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9375\n",
            "Specificity :  0.9629629629629629\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9557522123893806\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  3\n",
            "False Negatives :  2\n",
            "True Negatives  :  78\n",
            "True Positives  :  30\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9375\n",
            "Specificity :  0.9629629629629629\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9557522123893806\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  1\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  4\n",
            "False Negatives :  12\n",
            "True Negatives  :  244\n",
            "True Positives  :  192\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9411764705882353\n",
            "Specificity :  0.9838709677419355\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9646017699115044\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  1\n",
            "False Negatives :  3\n",
            "True Negatives  :  61\n",
            "True Positives  :  48\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9411764705882353\n",
            "Specificity :  0.9838709677419355\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9646017699115044\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  2\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  4\n",
            "False Negatives :  0\n",
            "True Negatives  :  268\n",
            "True Positives  :  180\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9852941176470589\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9911504424778761\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  1\n",
            "False Negatives :  0\n",
            "True Negatives  :  67\n",
            "True Positives  :  45\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  1.0\n",
            "Specificity :  0.9852941176470589\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9911504424778761\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  3\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  12\n",
            "False Negatives :  8\n",
            "True Negatives  :  280\n",
            "True Positives  :  152\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.95\n",
            "Specificity :  0.958904109589041\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9557522123893806\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  3\n",
            "False Negatives :  2\n",
            "True Negatives  :  70\n",
            "True Positives  :  38\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.95\n",
            "Specificity :  0.958904109589041\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9557522123893806\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  4\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  0\n",
            "False Negatives :  8\n",
            "True Negatives  :  276\n",
            "True Positives  :  168\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9545454545454546\n",
            "Specificity :  1.0\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9823008849557522\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  0\n",
            "False Negatives :  2\n",
            "True Negatives  :  69\n",
            "True Positives  :  42\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9545454545454546\n",
            "Specificity :  1.0\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9823008849557522\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Logistic Regression using L1-norm regularization approach & MBGD\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  0\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  136\n",
            "False Negatives :  16\n",
            "True Negatives  :  188\n",
            "True Positives  :  112\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.875\n",
            "Specificity :  0.5802469135802469\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.6637168141592921\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  34\n",
            "False Negatives :  4\n",
            "True Negatives  :  47\n",
            "True Positives  :  28\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.875\n",
            "Specificity :  0.5802469135802469\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.6637168141592921\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  1\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  20\n",
            "False Negatives :  16\n",
            "True Negatives  :  228\n",
            "True Positives  :  188\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9215686274509803\n",
            "Specificity :  0.9193548387096774\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9203539823008849\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  5\n",
            "False Negatives :  4\n",
            "True Negatives  :  57\n",
            "True Positives  :  47\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9215686274509803\n",
            "Specificity :  0.9193548387096774\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9203539823008849\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  2\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  76\n",
            "False Negatives :  32\n",
            "True Negatives  :  196\n",
            "True Positives  :  148\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.8222222222222222\n",
            "Specificity :  0.7205882352941176\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7610619469026548\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  19\n",
            "False Negatives :  8\n",
            "True Negatives  :  49\n",
            "True Positives  :  37\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.8222222222222222\n",
            "Specificity :  0.7205882352941176\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7610619469026548\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  3\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  40\n",
            "False Negatives :  24\n",
            "True Negatives  :  252\n",
            "True Positives  :  136\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.85\n",
            "Specificity :  0.863013698630137\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8584070796460177\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  10\n",
            "False Negatives :  6\n",
            "True Negatives  :  63\n",
            "True Positives  :  34\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.85\n",
            "Specificity :  0.863013698630137\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8584070796460177\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  4\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  48\n",
            "False Negatives :  40\n",
            "True Negatives  :  228\n",
            "True Positives  :  136\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.7727272727272727\n",
            "Specificity :  0.8260869565217391\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8053097345132744\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  12\n",
            "False Negatives :  10\n",
            "True Negatives  :  57\n",
            "True Positives  :  34\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.7727272727272727\n",
            "Specificity :  0.8260869565217391\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8053097345132744\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Logistic Regression using L1-norm regularization approach & SGD\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  0\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  104\n",
            "False Negatives :  8\n",
            "True Negatives  :  220\n",
            "True Positives  :  120\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9375\n",
            "Specificity :  0.6790123456790124\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7522123893805309\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  26\n",
            "False Negatives :  2\n",
            "True Negatives  :  55\n",
            "True Positives  :  30\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9375\n",
            "Specificity :  0.6790123456790124\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7522123893805309\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  1\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  12\n",
            "False Negatives :  20\n",
            "True Negatives  :  236\n",
            "True Positives  :  184\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9019607843137255\n",
            "Specificity :  0.9516129032258065\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9292035398230089\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  3\n",
            "False Negatives :  5\n",
            "True Negatives  :  59\n",
            "True Positives  :  46\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9019607843137255\n",
            "Specificity :  0.9516129032258065\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9292035398230089\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  2\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  24\n",
            "False Negatives :  16\n",
            "True Negatives  :  248\n",
            "True Positives  :  164\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9111111111111111\n",
            "Specificity :  0.9117647058823529\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.911504424778761\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  6\n",
            "False Negatives :  4\n",
            "True Negatives  :  62\n",
            "True Positives  :  41\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.9111111111111111\n",
            "Specificity :  0.9117647058823529\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.911504424778761\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  3\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  44\n",
            "False Negatives :  40\n",
            "True Negatives  :  248\n",
            "True Positives  :  120\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.75\n",
            "Specificity :  0.8493150684931506\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8141592920353983\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  11\n",
            "False Negatives :  10\n",
            "True Negatives  :  62\n",
            "True Positives  :  30\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.75\n",
            "Specificity :  0.8493150684931506\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8141592920353983\n",
            "--------------------------------------------------------------------------------\n",
            "Fold:  4\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for training data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  76\n",
            "False Negatives :  44\n",
            "True Negatives  :  200\n",
            "True Positives  :  132\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.75\n",
            "Specificity :  0.7246376811594203\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7345132743362832\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics measured for testing data\n",
            "--------------------------------------------------------------------------------\n",
            "False Positives :  19\n",
            "False Negatives :  11\n",
            "True Negatives  :  50\n",
            "True Positives  :  33\n",
            "--------------------------------------------------------------------------------\n",
            "Sensitivity :  0.75\n",
            "Specificity :  0.7246376811594203\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.7345132743362832\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}