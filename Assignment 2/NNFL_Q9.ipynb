{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sgmaH80k8Ck"
      },
      "source": [
        "#Q9\n",
        "Implement a multi-channel 1D deep CNN architecture (as shown in Fig. 1) for the seven-class classification\n",
        "task. The input and the class labels are given in. mat file format. There is a total of 17160 number of\n",
        "instances present in both input and class-label data files. The input data for each instance is a\n",
        "multichannel time series (12-channel) with size as (12 Ã—800). The class label for each multichannel time\n",
        "series instance is given in the class_label.mat file. You can select the training and test instances using\n",
        "hold-out cross-validation (70% training, 10% validation, and 20% testing). The architecture of the multichannel deep CNN is given as follows. The number of filters, length of each filter, and number of neurons\n",
        "in the fully connected layers are shown in the following figure. Evaluate individual accuracy and overall\n",
        "accuracy. (Packages such as Scikitlearn, keras, tensorflow, pytorch etc. are allowed)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE9ybNtAlBCF",
        "outputId": "ee1d7c71-d9e2-48fe-c3c6-a6bb70890629"
      },
      "source": [
        "!pip install mat4py\n",
        "import keras \n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Conv1D, Dropout,MaxPooling1D,MaxPool1D\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import shuffle\n",
        "from mat4py import loadmat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mat4py in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MAKNQt5fzma"
      },
      "source": [
        "data_feats = sio.loadmat('input.mat')\n",
        "data_feats = pd.DataFrame(data_feats[\"x\"])\n",
        "data_feats = (np.asarray(data_feats)).T\n",
        "\n",
        "data_labels=sio.loadmat('class_label.mat') \n",
        "data_labels=np.asarray(data_labels[\"y\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c7OXeJmiU7a"
      },
      "source": [
        "X_feats = []\n",
        "for i in range(len(data_feats)):\n",
        "  X_feats.append(data_feats[i][0])\n",
        "X_feats=np.asarray(X_feats)\n",
        "X_feats=X_feats.transpose(0,2,1)\n",
        "for i in range(len(X_feats)):\n",
        "  X_feats[i]=preprocessing.normalize(X_feats[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcqcBmd_iWuw"
      },
      "source": [
        "Y_labels = []\n",
        "for i in range(len(data_labels)):\n",
        "  Y_labels.append(data_labels[i][0]-1)\n",
        "Y_labels=np.asarray(Y_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSy-9Y9liaOV"
      },
      "source": [
        "training_data_X, testing_data_X, training_data_Y, testing_data_Y = train_test_split(X_feats, Y_labels, test_size = 2/10, train_size = 8/10, random_state = 0)\n",
        "training_data_X, validation_data_X, training_data_Y, validation_data_Y = train_test_split(training_data_X, training_data_Y, test_size=1/8, train_size=7/8, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zKD544iamf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(kernel_size=7, filters=20, activation='relu', input_shape=(800,12)))\n",
        "model.add(MaxPooling1D(pool_size = 3, strides = 3))\n",
        "model.add(Conv1D(kernel_size = 7, filters = 60, activation = 'relu'))\n",
        "model.add(MaxPooling1D(pool_size = 3, strides = 3))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Conv1D(filters = 120, kernel_size = 7))\n",
        "model.add(Conv1D(filters = 120, kernel_size = 7))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2000, activation = 'relu'))\n",
        "model.add(Dense(700))\n",
        "model.add(Dense(50))\n",
        "model.add(Dense(7, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCyLtHuEicwP",
        "outputId": "c4686447-e163-4f1a-9ab6-a9b7f5607010"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 794, 20)           1700      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 264, 20)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 258, 60)           8460      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 86, 60)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 86, 60)            0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 80, 120)           50520     \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 74, 120)           100920    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8880)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2000)              17762000  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 700)               1400700   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                35050     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 357       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,359,707\n",
            "Trainable params: 19,359,707\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V00F9NMNid8g",
        "outputId": "738fddd0-4e60-402b-a673-25c23275ccc8"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history=model.fit(training_data_X, training_data_Y, epochs=10, batch_size=1000, validation_data = (validation_data_X, validation_data_Y))\n",
        "print(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 56s 4s/step - loss: 3.3170 - accuracy: 0.2605 - val_loss: 1.5590 - val_accuracy: 0.4266\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 54s 4s/step - loss: 1.1386 - accuracy: 0.6311 - val_loss: 0.5840 - val_accuracy: 0.7686\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 54s 4s/step - loss: 0.3544 - accuracy: 0.8902 - val_loss: 0.0763 - val_accuracy: 0.9808\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 54s 4s/step - loss: 0.1103 - accuracy: 0.9632 - val_loss: 0.0387 - val_accuracy: 0.9854\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 55s 4s/step - loss: 0.0723 - accuracy: 0.9756 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 54s 4s/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 54s 4s/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 3.0739e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 58s 4s/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 1.9825e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 55s 4s/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.6248e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 55s 4s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 9.4339e-05 - val_accuracy: 1.0000\n",
            "<keras.callbacks.History object at 0x7fd2b47a9150>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kL1ugGKAEgK"
      },
      "source": [
        "# NNFL Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omj7b7rT_iRC",
        "outputId": "84d8f314-031a-4abc-afc0-6bdc11708e8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmgBJdcAAz5",
        "outputId": "ea25fe4a-d619-4780-e459-246ffa54923a"
      },
      "source": [
        "# Changing directory to the directory containing dataset\n",
        "%cd drive/MyDrive/NNFL/Data_A2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meFTsfIpAeGP",
        "outputId": "1fb8a342-2162-4262-f703-1f2d6d6a2c49"
      },
      "source": [
        "# listing datasets\n",
        "%ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1234719\n",
            "-rw------- 1 root root     637638 Oct 31 04:55 Assignment2.pdf\n",
            "-rw------- 1 root root        259 Oct 31 04:57 class_label.mat\n",
            "-rw------- 1 root root      40295 Oct 31 04:57 data55.xlsx\n",
            "-rw------- 1 root root      21269 Oct 31 04:55 data5.xlsx\n",
            "-rw------- 1 root root 1263647365 Oct 31 04:58 input.mat\n",
            "drwx------ 2 root root       4096 Nov 18 05:58 \u001b[0m\u001b[01;34mlogs\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "monX5050Awmc"
      },
      "source": [
        "# libraries required\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wDLjGQSaEU"
      },
      "source": [
        "# supressing warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}