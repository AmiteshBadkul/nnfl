{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNFL_Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRwdnNvqCj"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kL1ugGKAEgK"
      },
      "source": [
        "# NNFL Assignment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omj7b7rT_iRC",
        "outputId": "84d8f314-031a-4abc-afc0-6bdc11708e8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmgBJdcAAz5",
        "outputId": "ea25fe4a-d619-4780-e459-246ffa54923a"
      },
      "source": [
        "# Changing directory to the directory containing dataset\n",
        "%cd drive/MyDrive/NNFL/Data_A2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NNFL/Data_A2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meFTsfIpAeGP",
        "outputId": "1fb8a342-2162-4262-f703-1f2d6d6a2c49"
      },
      "source": [
        "# listing datasets\n",
        "%ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1234719\n",
            "-rw------- 1 root root     637638 Oct 31 04:55 Assignment2.pdf\n",
            "-rw------- 1 root root        259 Oct 31 04:57 class_label.mat\n",
            "-rw------- 1 root root      40295 Oct 31 04:57 data55.xlsx\n",
            "-rw------- 1 root root      21269 Oct 31 04:55 data5.xlsx\n",
            "-rw------- 1 root root 1263647365 Oct 31 04:58 input.mat\n",
            "drwx------ 2 root root       4096 Nov 18 05:58 \u001b[0m\u001b[01;34mlogs\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "monX5050Awmc"
      },
      "source": [
        "# libraries required\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wDLjGQSaEU"
      },
      "source": [
        "# supressing warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HCYO5XXPqdq"
      },
      "source": [
        "# Q2 \n",
        "Implement kernel perceptron algorithm for the classification task. The dataset (data55.xlsx) contains 19\n",
        "features and the last column is the output (class label). You can use hold-out cross-validation (70, 10, and\n",
        "20%) for the selection of training, validation and test instances. Evaluate accuracy, sensitivity and\n",
        "specificity measures for the evaluation of test instances. Evaluate the classification performance\n",
        "separately using linear, RBF, and polynomial kernels (Packages such as Scikitlearn, keras, tensorflow,\n",
        "pytorch etc. are not allowed).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5OwTK6D2vOt"
      },
      "source": [
        "def metrics(Y_true, Y_pred):\n",
        "    FP=0 # For counting the False Positives\n",
        "    FN=0 # For counting the False Negatives\n",
        "    TN=0 # For counting the True Negatives\n",
        "    TP=0 # For counting the True Positives\n",
        "\n",
        "    for i in range(len(Y_true)):\n",
        "      if Y_true[i]==1:\n",
        "        if Y_pred[i]==1:\n",
        "          TP+=1\n",
        "        else:\n",
        "          FN+=1\n",
        "      else:\n",
        "        if Y_pred[i]==0:\n",
        "          TN+=1\n",
        "        else:\n",
        "          FP+=1\n",
        "\n",
        "    print('{}'.format('-'*75))\n",
        "    \n",
        "    sens= TP/(TP+FN)\n",
        "    spes = TN/(TN+FP)\n",
        "\n",
        "    print(\"Sensitivity : \", sens)\n",
        "    print(\"Specificity : \", spes)\n",
        "    print(\"Accuracy ((TN+TP)/(TN+TP+FN+FP)) : \", ((TP+TN)/(TN+FN+TP+FP)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hl6xYzCPwey"
      },
      "source": [
        "def polynomialKernel(idx_list, idx, lower, upper, deg):\n",
        "    idx = [*idx]\n",
        "    if deg == 0:\n",
        "        idx_list.append(idx)\n",
        "        return\n",
        "    for i in range(lower, upper):\n",
        "        idx.append(i)\n",
        "        polynomialKernel(idx_list, idx, i, upper, deg-1)\n",
        "        idx = idx[0:-1]\n",
        "\n",
        "def polynomialFeats(X, deg):\n",
        "    row, col = X.shape\n",
        "    feats = []\n",
        "    for i in range(1, deg+1):\n",
        "        l = []\n",
        "        polynomialKernel(l, [], 0, col, i)\n",
        "        for idx in l:\n",
        "            x_temp = np.ones((row,))\n",
        "            for idx in idx:\n",
        "                x_temp = x_temp * X[:, idx]\n",
        "            feats.append(x_temp)\n",
        "    return np.stack(feats, axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECasKjbEQfjH"
      },
      "source": [
        "def resultQ2(filename = 'data55.xlsx'):\n",
        "  dataset = pd.read_excel(filename, header = None)\n",
        "\n",
        "  row, col = dataset.shape\n",
        "  feats = col - 1 \n",
        "\n",
        "  # normalization\n",
        "  dataset.loc[:, dataset.columns != feats] = (dataset.loc[:, dataset.columns != feats]-dataset.loc[:, dataset.columns != feats].mean(axis=0))/dataset.loc[:, dataset.columns != feats].std(axis=0)\n",
        "  \n",
        "  # spliting dataset into train test and val\n",
        "  training_data, validation_data, testing_data = np.split(dataset.sample(frac=1),[int(0.7*len(dataset)), int(0.8*len(dataset))])\n",
        "\n",
        "  training_data = np.array(training_data)\n",
        "  validation_data = np.array(validation_data)\n",
        "  testing_data = np.array(testing_data)\n",
        "  training_data_X = polynomialFeats(training_data[:, :feats], 4)\n",
        "  training_data_y = training_data[:, feats]\n",
        "  validation_data_X = polynomialFeats(validation_data[:, :feats], 4)\n",
        "  validation_data_y = validation_data[:, feats]\n",
        "  testing_data_X = polynomialFeats(testing_data[:, :feats], 4)\n",
        "  testing_data_y = testing_data[:, feats]\n",
        "\n",
        "  train_row, train_col = training_data_X.shape\n",
        "\n",
        "  W = np.random.randn(train_col)  \n",
        "  bias = np.ones(train_row)\n",
        "\n",
        "  W, bias = perceptron(training_data_X, training_data_y, bias, W)\n",
        "  print(\"The Weights after training is as follows: \\n\")\n",
        "  pprint(W)\n",
        "  print(\"The Bias after training is as follows: \", bias[0])\n",
        "  print('{}'.format('-'*75))\n",
        "\n",
        "  train_pred = pred_eval(training_data_X, W, bias)\n",
        "  train_pred = np.where(train_pred > 0.5, 1,0)\n",
        "  print(\"Training Accuracy: \\n\")\n",
        "  metrics(train_pred, training_data_y)\n",
        "  print('{}'.format('-'*75))\n",
        "\n",
        "  test_pred = pred_eval(testing_data_X, W, bias)\n",
        "  test_pred = np.where(test_pred > 0.5, 1,0)\n",
        "  print(\"Testing Accuracy: \\n\")\n",
        "  metrics(test_pred, testing_data_y)\n",
        "  print('{}'.format('-'*75))\n",
        "  \n",
        "  validation_pred = pred_eval(validation_data_X, W, bias)\n",
        "  validation_pred = np.where(validation_pred > 0.5, 1,0)\n",
        "  print(\"Validation Accuracy: \\n\")\n",
        "  metrics(validation_pred, validation_data_y)\n",
        "  print('{}'.format('-'*75))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqbRKsRo8yUA",
        "outputId": "a6bf4dfa-e8c9-49b1-8fbb-d791614a0066"
      },
      "source": [
        "resultQ2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Weights after training is as follows: \n",
            "\n",
            "array([ 0.13049155, -1.31189354, -0.67991826, ...,  0.57346655,\n",
            "       -0.80864538,  0.11325281])\n",
            "The Bias after training is as follows:  1.0155357007732724\n",
            "---------------------------------------------------------------------------\n",
            "Training Accuracy: \n",
            "\n",
            "Sensitivity :  0.9456521739130435\n",
            "Specificity :  0.8906256289423758\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9230769230769231\n",
            "---------------------------------------------------------------------------\n",
            "Testing Accuracy: \n",
            "\n",
            "Sensitivity :  0.8765432098765432\n",
            "Specificity :  0.9523809523809523\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.9254385964912281\n",
            "---------------------------------------------------------------------------\n",
            "Validation Accuracy: \n",
            "\n",
            "Sensitivity :  0.8833333333333333\n",
            "Specificity :  0.8414634146341463\n",
            "Accuracy ((TN+TP)/(TN+TP+FN+FP)) :  0.8591549295774648\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}